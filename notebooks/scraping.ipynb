{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a914fda5",
   "metadata": {},
   "source": [
    "# Telegram Medical Data Scraper\n",
    "\n",
    "This notebook demonstrates how to scrape medical data from Telegram channels using the asynchronous scraper module.\n",
    "\n",
    "## Target Channels\n",
    "- https://t.me/CheMed123\n",
    "- https://t.me/lobelia4cosmetics  \n",
    "- https://t.me/tikvahpharma\n",
    "\n",
    "## Features\n",
    "- Asynchronous scraping using Telethon\n",
    "- Rate limit handling\n",
    "- Error handling for various Telegram errors\n",
    "- Data storage in JSON format\n",
    "- Progress tracking and logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e30225f",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b97a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully\n",
      "üìÅ Current working directory: c:\\Users\\Admin\\OneDrive\\ACADEMIA\\10 Academy\\Week 7\\GitHub Repository\\telegram-medical-data-pipeline\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to Python path\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Import our scraper\n",
    "from scraper.telegram_scraper import TelegramScraper\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"üìÅ Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f71efe",
   "metadata": {},
   "source": [
    "## Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b289bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TELEGRAM_API_ID: ********\n",
      "‚úÖ TELEGRAM_API_HASH: ********************************\n",
      "‚úÖ TELEGRAM_PHONE: *************\n",
      "‚úÖ All required environment variables are set\n",
      "üìÅ Data directory exists: ..\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "# Check if .env file exists and load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Check required environment variables\n",
    "required_vars = ['TELEGRAM_API_ID', 'TELEGRAM_API_HASH', 'TELEGRAM_PHONE']\n",
    "missing_vars = []\n",
    "\n",
    "for var in required_vars:\n",
    "    value = os.getenv(var)\n",
    "    if not value:\n",
    "        missing_vars.append(var)\n",
    "    else:\n",
    "        print(f\"‚úÖ {var}: {'*' * len(value)}\")  # Hide actual values\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing environment variables: {missing_vars}\")\n",
    "    print(\"Please create a .env file with your Telegram API credentials\")\n",
    "else:\n",
    "    print(\"‚úÖ All required environment variables are set\")\n",
    "\n",
    "# Check data directory\n",
    "data_dir = Path(\"../data/raw\")\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"üìÅ Created data directory: {data_dir}\")\n",
    "else:\n",
    "    print(f\"üìÅ Data directory exists: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1688a1",
   "metadata": {},
   "source": [
    "## Initialize Scraper\n",
    "\n",
    "Let's create an instance of our TelegramScraper and test the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0b894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:05:01,965 - scraper.telegram_scraper - INFO - Initialized TelegramScraper with 3 target channels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraper initialized successfully\n",
      "ÔøΩÔøΩ Target channels: 3\n",
      "   - https://t.me/CheMed123\n",
      "   - https://t.me/lobelia4cosmetics\n",
      "   - https://t.me/tikvahpharma\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scraper\n",
    "try:\n",
    "    scraper = TelegramScraper()\n",
    "    print(\"‚úÖ Scraper initialized successfully\")\n",
    "    print(f\"ÔøΩÔøΩ Target channels: {len(scraper.target_channels)}\")\n",
    "    for channel in scraper.target_channels:\n",
    "        print(f\"   - {channel}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing scraper: {e}\")\n",
    "    scraper = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443df7c",
   "metadata": {},
   "source": [
    "## Test Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff0b63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:05:01,981 - telethon.network.mtprotosender - INFO - Connecting to 149.154.167.91:443/TcpFull...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÔøΩÔøΩ Testing connection to Telegram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:05:02,218 - telethon.network.mtprotosender - INFO - Connection to 149.154.167.91:443/TcpFull complete!\n",
      "2025-07-14 23:05:03,301 - scraper.telegram_scraper - INFO - Successfully connected to Telegram\n",
      "2025-07-14 23:05:03,303 - telethon.network.mtprotosender - INFO - Disconnecting from 149.154.167.91:443/TcpFull...\n",
      "2025-07-14 23:05:03,304 - telethon.network.mtprotosender - INFO - Disconnection from 149.154.167.91:443/TcpFull complete!\n",
      "2025-07-14 23:05:03,310 - scraper.telegram_scraper - INFO - Disconnected from Telegram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to Telegram\n",
      "‚úÖ Disconnected from Telegram\n"
     ]
    }
   ],
   "source": [
    "# Test connection to Telegram\n",
    "async def test_connection():\n",
    "    if not scraper:\n",
    "        print(\"‚ùå Scraper not initialized\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        print(\"ÔøΩÔøΩ Testing connection to Telegram...\")\n",
    "        connected = await scraper.connect()\n",
    "        \n",
    "        if connected:\n",
    "            print(\"‚úÖ Successfully connected to Telegram\")\n",
    "            await scraper.disconnect()\n",
    "            print(\"‚úÖ Disconnected from Telegram\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Failed to connect to Telegram\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the connection test\n",
    "connection_success = await test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27ecc3",
   "metadata": {},
   "source": [
    "## Scrape All Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db7938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:05:03,332 - telethon.network.mtprotosender - INFO - Connecting to 149.154.167.91:443/TcpFull...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÔøΩÔøΩ Starting to scrape all channels...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:05:03,549 - telethon.network.mtprotosender - INFO - Connection to 149.154.167.91:443/TcpFull complete!\n",
      "2025-07-14 23:05:04,778 - scraper.telegram_scraper - INFO - Successfully connected to Telegram\n",
      "2025-07-14 23:05:04,779 - scraper.telegram_scraper - INFO - Starting scrape for 3 channels\n",
      "2025-07-14 23:05:04,780 - scraper.telegram_scraper - INFO - Starting scrape for channel: CheMed123\n",
      "2025-07-14 23:05:04,780 - scraper.telegram_scraper - INFO - Starting to scrape channel: CheMed123\n",
      "2025-07-14 23:05:05,622 - scraper.telegram_scraper - INFO - Successfully scraped 63 messages from CheMed123\n",
      "2025-07-14 23:05:05,626 - scraper.telegram_scraper - INFO - Saved 63 messages to data/raw\\2025-07-14\\CheMed123\\messages.json\n",
      "2025-07-14 23:05:07,629 - scraper.telegram_scraper - INFO - Starting scrape for channel: lobelia4cosmetics\n",
      "2025-07-14 23:05:07,631 - scraper.telegram_scraper - INFO - Starting to scrape channel: lobelia4cosmetics\n",
      "2025-07-14 23:05:08,825 - scraper.telegram_scraper - INFO - Scraped 100 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:09,278 - scraper.telegram_scraper - INFO - Scraped 200 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:09,779 - scraper.telegram_scraper - INFO - Scraped 300 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:10,341 - scraper.telegram_scraper - INFO - Scraped 400 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:11,023 - scraper.telegram_scraper - INFO - Scraped 500 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:11,619 - scraper.telegram_scraper - INFO - Scraped 600 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:12,868 - scraper.telegram_scraper - INFO - Scraped 700 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:13,478 - scraper.telegram_scraper - INFO - Scraped 800 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:14,016 - scraper.telegram_scraper - INFO - Scraped 900 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:14,023 - scraper.telegram_scraper - INFO - Successfully scraped 965 messages from lobelia4cosmetics\n",
      "2025-07-14 23:05:14,054 - scraper.telegram_scraper - INFO - Saved 965 messages to data/raw\\2025-07-14\\lobelia4cosmetics\\messages.json\n",
      "2025-07-14 23:05:16,056 - scraper.telegram_scraper - INFO - Starting scrape for channel: tikvahpharma\n",
      "2025-07-14 23:05:16,057 - scraper.telegram_scraper - INFO - Starting to scrape channel: tikvahpharma\n",
      "2025-07-14 23:05:18,708 - scraper.telegram_scraper - INFO - Scraped 100 messages from tikvahpharma\n",
      "2025-07-14 23:05:20,057 - scraper.telegram_scraper - INFO - Scraped 200 messages from tikvahpharma\n",
      "2025-07-14 23:05:21,276 - scraper.telegram_scraper - INFO - Scraped 300 messages from tikvahpharma\n",
      "2025-07-14 23:05:22,353 - scraper.telegram_scraper - INFO - Scraped 400 messages from tikvahpharma\n",
      "2025-07-14 23:05:23,541 - scraper.telegram_scraper - INFO - Scraped 500 messages from tikvahpharma\n",
      "2025-07-14 23:05:24,846 - scraper.telegram_scraper - INFO - Scraped 600 messages from tikvahpharma\n",
      "2025-07-14 23:05:26,313 - scraper.telegram_scraper - INFO - Scraped 700 messages from tikvahpharma\n",
      "2025-07-14 23:05:27,566 - scraper.telegram_scraper - INFO - Scraped 800 messages from tikvahpharma\n",
      "2025-07-14 23:05:28,511 - scraper.telegram_scraper - INFO - Scraped 900 messages from tikvahpharma\n",
      "2025-07-14 23:05:28,521 - scraper.telegram_scraper - INFO - Successfully scraped 946 messages from tikvahpharma\n",
      "2025-07-14 23:05:28,565 - scraper.telegram_scraper - INFO - Saved 946 messages to data/raw\\2025-07-14\\tikvahpharma\\messages.json\n",
      "2025-07-14 23:05:30,577 - scraper.telegram_scraper - INFO - Scraping completed. 3/3 channels successful. Total messages scraped: 1974\n",
      "2025-07-14 23:05:30,580 - telethon.network.mtprotosender - INFO - Disconnecting from 149.154.167.91:443/TcpFull...\n",
      "2025-07-14 23:05:30,584 - telethon.network.mtprotosender - INFO - Disconnection from 149.154.167.91:443/TcpFull complete!\n",
      "2025-07-14 23:05:30,597 - scraper.telegram_scraper - INFO - Disconnected from Telegram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Scraping Summary:\n",
      "------------------------------\n",
      "‚úÖ CheMed123\n",
      "   Messages: 63\n",
      "   Status: success\n",
      "   File: data/raw\\2025-07-14\\CheMed123\\messages.json\n",
      "\n",
      "‚úÖ lobelia4cosmetics\n",
      "   Messages: 965\n",
      "   Status: success\n",
      "   File: data/raw\\2025-07-14\\lobelia4cosmetics\\messages.json\n",
      "\n",
      "‚úÖ tikvahpharma\n",
      "   Messages: 946\n",
      "   Status: success\n",
      "   File: data/raw\\2025-07-14\\tikvahpharma\\messages.json\n",
      "\n",
      "==================================================\n",
      "üìà Final Summary:\n",
      "   Successful channels: 3/3\n",
      "   Total messages scraped: 1974\n",
      "   Timestamp: 2025-07-14 23:05:30\n"
     ]
    }
   ],
   "source": [
    "# Function to scrape all channels\n",
    "async def scrape_all_channels():\n",
    "    \"\"\"Scrape all target channels\"\"\"\n",
    "    if not scraper:\n",
    "        print(\"‚ùå Scraper not initialized\")\n",
    "        return []\n",
    "    \n",
    "    print(\"ÔøΩÔøΩ Starting to scrape all channels...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Connect to Telegram\n",
    "        if not await scraper.connect():\n",
    "            print(\"‚ùå Failed to connect to Telegram\")\n",
    "            return []\n",
    "        \n",
    "        # Scrape all channels\n",
    "        results = await scraper.scrape_all_channels()\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nüìä Scraping Summary:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        total_messages = 0\n",
    "        successful_channels = 0\n",
    "        \n",
    "        for result in results:\n",
    "            status_icon = \"‚úÖ\" if result['status'] == 'success' else \"‚ùå\"\n",
    "            print(f\"{status_icon} {result['channel_name']}\")\n",
    "            print(f\"   Messages: {result['message_count']}\")\n",
    "            print(f\"   Status: {result['status']}\")\n",
    "            \n",
    "            if result['file_path']:\n",
    "                print(f\"   File: {result['file_path']}\")\n",
    "            \n",
    "            if result['error']:\n",
    "                print(f\"   Error: {result['error']}\")\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                successful_channels += 1\n",
    "                total_messages += result['message_count']\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üìà Final Summary:\")\n",
    "        print(f\"   Successful channels: {successful_channels}/{len(results)}\")\n",
    "        print(f\"   Total messages scraped: {total_messages}\")\n",
    "        print(f\"   Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        await scraper.disconnect()\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in scraping: {e}\")\n",
    "        await scraper.disconnect()\n",
    "        return []\n",
    "\n",
    "# Run the scraping\n",
    "all_results = await scrape_all_channels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e54f5f",
   "metadata": {},
   "source": [
    "## Data Summary\n",
    "\n",
    "Let's create a summary of all scraped data across all channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0c6b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating comprehensive data summary...\n",
      "==================================================\n",
      "üìÅ Total files: 3\n",
      "üìù Total messages: 1974\n",
      "üìÖ Date range: 2022-09-05T09:57:09+00:00 to 2025-07-14T18:27:36+00:00\n",
      "üìä Total size: 2.74 MB\n",
      "\n",
      "üì° Channels:\n",
      "   CheMed123:\n",
      "     Files: 1\n",
      "     Messages: 63\n",
      "     Size: 0.05 MB\n",
      "   lobelia4cosmetics:\n",
      "     Files: 1\n",
      "     Messages: 965\n",
      "     Size: 0.98 MB\n",
      "   tikvahpharma:\n",
      "     Files: 1\n",
      "     Messages: 946\n",
      "     Size: 1.71 MB\n"
     ]
    }
   ],
   "source": [
    "# Function to create comprehensive data summary\n",
    "def create_data_summary():\n",
    "    \"\"\"Create a comprehensive summary of all scraped data\"\"\"\n",
    "    data_dir = Path(\"../notebooks/data/raw/2025-07-14/\")\n",
    "    \n",
    "    if not data_dir.exists():\n",
    "        print(\"‚ùå Data directory does not exist\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä Creating comprehensive data summary...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Find all JSON files\n",
    "    json_files = list(data_dir.rglob(\"*.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(\"‚ùå No data files found\")\n",
    "        return\n",
    "    \n",
    "    summary = {\n",
    "        'total_files': len(json_files),\n",
    "        'total_messages': 0,\n",
    "        'channels': {},\n",
    "        'date_range': {'earliest': None, 'latest': None},\n",
    "        'file_sizes': {},\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            # Get file info\n",
    "            file_size = json_file.stat().st_size\n",
    "            file_size_mb = file_size / (1024 * 1024)\n",
    "            \n",
    "            # Extract channel name from path\n",
    "            channel_name = json_file.parent.name\n",
    "            \n",
    "            # Load data\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            message_count = len(data) if isinstance(data, list) else 0\n",
    "            \n",
    "            # Update summary\n",
    "            summary['total_messages'] += message_count\n",
    "            summary['file_sizes'][str(json_file)] = file_size_mb\n",
    "            \n",
    "            if channel_name not in summary['channels']:\n",
    "                summary['channels'][channel_name] = {\n",
    "                    'files': 0,\n",
    "                    'messages': 0,\n",
    "                    'total_size_mb': 0\n",
    "                }\n",
    "            \n",
    "            summary['channels'][channel_name]['files'] += 1\n",
    "            summary['channels'][channel_name]['messages'] += message_count\n",
    "            summary['channels'][channel_name]['total_size_mb'] += file_size_mb\n",
    "            \n",
    "            # Update date range\n",
    "            if data:\n",
    "                dates = [msg.get('message_date', '') for msg in data if msg.get('message_date')]\n",
    "                if dates:\n",
    "                    if not summary['date_range']['earliest'] or min(dates) < summary['date_range']['earliest']:\n",
    "                        summary['date_range']['earliest'] = min(dates)\n",
    "                    if not summary['date_range']['latest'] or max(dates) > summary['date_range']['latest']:\n",
    "                        summary['date_range']['latest'] = max(dates)\n",
    "            \n",
    "        except Exception as e:\n",
    "            summary['errors'].append(f\"Error reading {json_file}: {e}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"üìÅ Total files: {summary['total_files']}\")\n",
    "    print(f\"üìù Total messages: {summary['total_messages']}\")\n",
    "    print(f\"üìÖ Date range: {summary['date_range']['earliest']} to {summary['date_range']['latest']}\")\n",
    "    print(f\"üìä Total size: {sum(summary['file_sizes'].values()):.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüì° Channels:\")\n",
    "    for channel, stats in summary['channels'].items():\n",
    "        print(f\"   {channel}:\")\n",
    "        print(f\"     Files: {stats['files']}\")\n",
    "        print(f\"     Messages: {stats['messages']}\")\n",
    "        print(f\"     Size: {stats['total_size_mb']:.2f} MB\")\n",
    "    \n",
    "    if summary['errors']:\n",
    "        print(f\"\\n‚ùå Errors:\")\n",
    "        for error in summary['errors']:\n",
    "            print(f\"   {error}\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Create the summary\n",
    "data_summary = create_data_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
